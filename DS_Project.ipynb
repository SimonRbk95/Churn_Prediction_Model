{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2a13b87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier # Import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Import feature and tree visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from matplotlib import style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1a39bb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "start_features = ['Age', 'BusinessTravel', 'DailyRate', 'Department',\n",
    "       'DistanceFromHome', 'Education', 'EducationField',\n",
    "        'EnvironmentSatisfaction', 'Gender', 'HourlyRate',\n",
    "       'JobInvolvement', 'JobLevel', 'JobRole', 'JobSatisfaction',\n",
    "       'MaritalStatus', 'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked',\n",
    "        'OverTime', 'PercentSalaryHike', 'PerformanceRating',\n",
    "       'RelationshipSatisfaction', 'StockOptionLevel',\n",
    "       'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance',\n",
    "       'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n",
    "       'YearsWithCurrManager']\n",
    "target = \"Attrition\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "addcf1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # create dataframe with project's data set\n",
    "    df = pd.read_csv('HR.csv')\n",
    "    \n",
    "    # clean the data\n",
    "    clean_df = clean_data(df)\n",
    "\n",
    "    # create the model, decsion tree or random forest\n",
    "    # return required data to test accuracy\n",
    "    y_test, y_pred = random_forest(clean_df)\n",
    "    \n",
    "    # print model accuracy to terminal\n",
    "    model_accuracy(y_test, y_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "006372e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_categoricals(df):\n",
    "    cat_features = []\n",
    "    \n",
    "    # extract a list of all categorical features for feature engineering except target column\n",
    "    for col_header in df.columns:\n",
    "        if col_header != target and df.dtypes[col_header] == object:\n",
    "            cat_features.append(col_header)         \n",
    "    return cat_features\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "43892ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    # drop columns that are not needed\n",
    "    for col_header in df.columns:\n",
    "        if col_header not in start_features and col_header != target:\n",
    "            df.drop(col_header, axis=1, inplace=True)\n",
    "            \n",
    "    # drop rows that contain at least one empty cell\n",
    "    df.dropna(axis='rows', thresh=1)\n",
    "    \n",
    "    # feature enigneering for categorical data\n",
    "    clean_df = pd.get_dummies(data=df, columns=extract_categoricals(df))\n",
    "    \n",
    "    return clean_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f7b16df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(clean_df):\n",
    "    \n",
    "    # get target variable and exclude it from features\n",
    "    y = clean_df.pop(target)\n",
    "      \n",
    "    # get new feature list\n",
    "    features = clean_df.columns.tolist()\n",
    "    \n",
    "    # get feature data\n",
    "    X = clean_df[features] # Features Matrix\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "41c11b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(clean_df):\n",
    "    # get features matrix X and target variable y\n",
    "    X, y = feature_selection(clean_df)\n",
    "    \n",
    "    # Split dataset into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "    # Create Decision Tree classifer object\n",
    "    clf = DecisionTreeClassifier(criterion='gini', max_depth=3) # use criterion=entropy as attribute or default gini\n",
    "\n",
    "    # Train Decision Tree Classifer\n",
    "    clf = clf.fit(X_train,y_train)\n",
    "    \n",
    "    # Predict the response for test dataset\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # plot decision tree\n",
    "    plot_tree(clf, X.columns.tolist())\n",
    "    \n",
    "    return y_test, y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c1261d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(clean_df):\n",
    "    # get features matrix X and target variable y\n",
    "    X, y = feature_selection(clean_df)\n",
    "    \n",
    "    # Split dataset into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "    # Create ranodm forest\n",
    "    clf = RandomForestClassifier(criterion='gini', max_depth=30, n_estimators=200) \n",
    "\n",
    "    # Train random forest Classifer\n",
    "    clf = clf.fit(X_train,y_train)\n",
    "    \n",
    "    # Predict the response for test dataset\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    return y_test, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "32599322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tree(clf, features):\n",
    "    \n",
    "    # Setting dpi = 300 to make image clearer than default\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(30,30), dpi=300)\n",
    "\n",
    "    tree.plot_tree(clf,\n",
    "           feature_names=features,\n",
    "           class_names=[\"No\",\"Yes\"],\n",
    "           filled=True,\n",
    "           fontsize=15);\n",
    "\n",
    "    fig.savefig('tree.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fed5aad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy(y_test, y_pred):\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3becbb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_imbalance():\n",
    "    # visualize imbalance of Attrition data\n",
    "    print(y.value_counts())\n",
    "    pass\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b943c562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance():\n",
    "    # visualize feature importance based on spefici metric\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6cb3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_imbalance():\n",
    "    #adjust target data imbalance by over/undersampling\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8cfc8e62",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8435374149659864\n",
      "[[359   5]\n",
      " [ 64  13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.85      0.99      0.91       364\n",
      "         Yes       0.72      0.17      0.27        77\n",
      "\n",
      "    accuracy                           0.84       441\n",
      "   macro avg       0.79      0.58      0.59       441\n",
      "weighted avg       0.83      0.84      0.80       441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e027125",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
